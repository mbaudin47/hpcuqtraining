{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Uncertainty Propagation\n",
    "\n",
    "This example aims at introducing some basics of uncertainty propagation with OpenTURNS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openturns as ot\n",
    "from openturns.viewer import View\n",
    "import pylab as pl\n",
    "import otwrapy as otw\n",
    "import os\n",
    "from time import sleep\n",
    "import socket\n",
    "from openturns import coupling_tools\n",
    "from xml.dom import minidom\n",
    "from tempfile import mkdtemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check parallelisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this example, we use the cluster [Poincare](https://groupes.renater.fr/wiki/poincare/public/description_de_poincare).\n",
    "* we started an interactive session of loadleveler using llrun -f loadLeveler_script\n",
    "* Check the status of your job in the job manager (here: LoadLeveler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!llq -u adumas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Definition of the probabilistic model of input variables\n",
    "\n",
    "Let first define the marginal (univariate) distribution of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sample_E = ot.Sample.ImportFromCSVFile(\"sample_E.csv\")\n",
    "kernel_smoothing = ot.KernelSmoothing(ot.Normal())\n",
    "bandwidth = kernel_smoothing.computeSilvermanBandwidth(sample_E)\n",
    "E = kernel_smoothing.build(sample_E, bandwidth)\n",
    "E.setDescription(['Young modulus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "F = ot.LogNormal()\n",
    "F.setParameter(ot.LogNormalMuSigma()([30000, 9000, 15000]))\n",
    "F.setDescription(['Load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "L = ot.Uniform(250, 260)\n",
    "L.setDescription(['Length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "I = ot.Beta(2.5, 4, 310, 450)\n",
    "I.setDescription(['Inertia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We now fix the order of the marginal distributions in the joint distribution. Order must match in the implementation of the physical model (to come)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "marginal_distributions = [F, E, L, I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(15, 3))\n",
    "drawables = [marginal_distribution.drawPDF() for marginal_distribution in marginal_distributions]\n",
    "axes = [fig.add_subplot(1, 4, i) for i in range(1, 5)]\n",
    "for axis, drawable in zip(axes, drawables):\n",
    "    _ = View(drawable, figure=fig, axes=[axis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let then define the dependence structure as a Normal copula with a single non-zero Spearman correlation between components 2 and 3 of the final random vector, that is $L$ and $I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "SR_cor = ot.CorrelationMatrix(len(marginal_distributions))\n",
    "SR_cor[2, 3] = -0.2\n",
    "copula = ot.NormalCopula(ot.NormalCopula.GetCorrelationFromSpearmanCorrelation(SR_cor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Eventually the input joint distribution is defined as a *composed distribution*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_distribution = ot.ComposedDistribution(marginal_distributions, copula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Definition of the physical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, let us define a Python function that implements the model $\\mathcal{M}: \\mathbf{x} \\mapsto \\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from openturns import coupling_tools\n",
    "from xml.dom import minidom\n",
    "\n",
    "class Wrapper(ot.OpenTURNSPythonFunction):\n",
    "    \"\"\"\n",
    "    Wrapper of the beam code\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sleep_time=0):\n",
    "        '''\n",
    "        Initialize the OpenTURNSPythonFunction.\n",
    "        \n",
    "        number of inputs = 4\n",
    "        number of outputs = 1\n",
    "        \n",
    "        Args\n",
    "        sleep_time -- float, default 0, time the _exec must wait to run the external code.\n",
    "        '''\n",
    "\n",
    "        super(Wrapper, self).__init__(4, 1)\n",
    "        \n",
    "        # define attributes for the template file and the executable\n",
    "        self.cwd = os.getcwd()\n",
    "        self.template_path = self.cwd + os.sep + \"beam\" + os.sep + \"beam_input_template.xml\"\n",
    "        self.executable_path = self.cwd + os.sep + \"beam\" + os.sep + \"beam -v -x beam.xml\"\n",
    "        self.sleep_time = sleep_time\n",
    "\n",
    "    def _exec(self, X):\n",
    "        '''\n",
    "        \n",
    "        Args\n",
    "        X -- OpenTurns Point object, input values of the model.\n",
    "        '''\n",
    "        X = ot.Point(X)\n",
    "        \n",
    "        # manage the execution inside a temporary directory thanks to otwrappy\n",
    "        with otw.TempWorkDir(base_temp_work_dir=\"/tmp\", cleanup=False, prefix=\"ot-beam-\"):\n",
    "            \n",
    "            # wait\n",
    "            sleep(self.sleep_time)\n",
    "            \n",
    "            # create input\n",
    "            self._create_input_file(X)\n",
    "            \n",
    "            # run executable\n",
    "            self._run()\n",
    "            \n",
    "            # parse output\n",
    "            Y = self._parse_output()\n",
    "            ot.Log.User(socket.gethostname())\n",
    "            #ot.Log.Flush()\n",
    "        return [Y]\n",
    "    \n",
    "    def _create_input_file(self, X):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        ot.coupling_tools.replace(\n",
    "              self.template_path,\n",
    "              'beam.xml',\n",
    "              ['@F','@E','@L','@I'],\n",
    "             X)\n",
    "        \n",
    "    def _run(self):\n",
    "        ot.coupling_tools.execute(self.executable_path)\n",
    "    \n",
    "    def _parse_output(self):\n",
    "        xmldoc = minidom.parse('_beam_outputs_.xml')\n",
    "        itemlist = xmldoc.getElementsByTagName('outputs')\n",
    "        deviation = float(itemlist[0].attributes['deviation'].value)\n",
    "        return(deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sequential Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a sequential `Function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model_serial = ot.Function(Wrapper(0.2))\n",
    "model_serial.setDescription(list(X_distribution.getDescription()) + [\"deviation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the sequential function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_distribution.getMean()\n",
    "print(mean)\n",
    "model_serial(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributed `Function` using `OtWraPy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a parallelized function using otw.Parallelizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backend = 'ipyparallel', 'joblib', 'pathos' or 'multiprocessing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = otw.Parallelizer(model_serial, backend='multiprocessing', n_cpus=2, verbosity=5)\n",
    "model.setDescription(list(X_distribution.getDescription()) + ['deviation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's execute the function on a sequence of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y = [model_serial(x) for x in X_distribution.getSample(sampleSize)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_inputs = X_distribution.getSample(sampleSize)\n",
    "%time some_outputs = model(some_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "inputs_outputs = ot.Sample(some_inputs)\n",
    "inputs_outputs.stack(some_outputs)\n",
    "inputs_outputs[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Class : ', model.getClassName())\n",
    "print('Input : ', model.getDescription())\n",
    "print('Ouput : ', model.getOutputDescription())\n",
    "print('Evaluation : ', model.getEvaluation())\n",
    "print('Gradient : ', model.getGradient())\n",
    "print('Hessian : ', model.getHessian())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fine setup the `Function`\n",
    "OpenTURNS implements a cache mechanism that stores function calls (input and output) in order to save useless repeated calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.enableCache()\n",
    "print(\n",
    "    \"Current cache max size is %d.\"\n",
    "    % ot.ResourceMap.GetAsUnsignedInteger(\"cache-max-size\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now set the gradient and hessian implementations using **finite difference schemes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setGradient(\n",
    "    ot.NonCenteredFiniteDifferenceGradient(\n",
    "        np.array(X_distribution.getStandardDeviation()) * 5e-6,\n",
    "        model.getEvaluation()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setHessian(\n",
    "    ot.CenteredFiniteDifferenceHessian(\n",
    "        np.array(X_distribution.getStandardDeviation()) * 5e-4,\n",
    "        model.getEvaluation()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Definition of the output random vector\n",
    "\n",
    "The output distribution is unknown, but we can make a random vector out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_random_vector = ot.CompositeRandomVector(model, ot.RandomVector(X_distribution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Central tendancy analysis\n",
    "\n",
    "## Monte Carlo simulation\n",
    "\n",
    "One seeks here to evaluate the characteristics of the central part (location and spread, that is: mean or median and variance or interquartile) of the probability distribution of the variable deviation $Y$ by means of Monte Carlo (say pseudo-random) sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sample_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ot.RandomGenerator.SetSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Y_sample = Y_random_vector.getSample(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `getSample` method of the output random vector generates a sample out of the input distribution and propagate it through our model. Now we can estimate summary statistics from that sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Y_mean = Y_sample.computeMean()[0]\n",
    "Y_var = Y_sample.computeVariance()[0]\n",
    "Y_stdv = Y_sample.computeStandardDeviationPerComponent()[0]\n",
    "Y_skew = Y_sample.computeSkewness()[0]\n",
    "Y_kurt = Y_sample.computeKurtosis()[0]\n",
    "\n",
    "print(\"----------------------------\")\n",
    "print(\"Response sample statistics  \")\n",
    "print(\"----------------------------\")\n",
    "print(\"Size                  = %d\" % Y_sample.getSize())\n",
    "print(\"Mean                  = %.2f\" % Y_mean)\n",
    "print(\"Variance              = %.2f\" % Y_var )\n",
    "print(\"Standart-deviation    = %.2f\" % Y_stdv)\n",
    "print(\"Skewness              = %.2f\" % Y_skew)\n",
    "print(\"Kurtosis              = %.2f\" % Y_kurt)\n",
    "print(\"Median                = %.2f\" % Y_sample.computeQuantile(.5)[0])\n",
    "print(\"Interquartile         = [%.2f, %.2f]\" % (Y_sample.computeQuantile(.25)[0], Y_sample.computeQuantile(.75)[0]))\n",
    "print(\"CI at 95 %%            = [%.2f, %.2f]\" % (Y_sample.computeQuantile(.025)[0],Y_sample.computeQuantile(.975)[0]))\n",
    "print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computation of the confidence intervals at 95% of the mean and variance estimators of $Y$ obtained from this sample\n",
    "\n",
    "Since sampling is a random experiment, statistics may differ from one sample to the other. Fortunately, the estimation theory provides theorem enabling convergence diagnostics. For instance, the following two theorems provides the asymptotic distribution for the mean and variance estimators. These distributions can then be used to compute confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_level = .95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The **central limit theorem** states that the empirical mean tends asymptotically to a Gaussian distribution:  \n",
    "\n",
    "$N \\longrightarrow \\infty,\\,\\,\\,\\,\\,\\,\\bar V \\sim \\mathcal{N} \\left( m,\\dfrac{\\sigma}{\\sqrt{N}}  \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mean_asymptotic_variance = Y_var / sample_size\n",
    "Y_mean_asymptotic_distribution = ot.Normal(Y_mean, np.sqrt(Y_mean_asymptotic_variance))\n",
    "Y_mean_confidence_interval = (\n",
    "    Y_mean_asymptotic_distribution.computeQuantile((1. - confidence_level) / 2.)[0],\n",
    "    Y_mean_asymptotic_distribution.computeQuantile(1. - (1. - confidence_level) / 2.)[0]\n",
    ")\n",
    "print(\"95%%-CI for the mean = [%.2f, %.2f]\" % Y_mean_confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Cochran's theorem** gives the asymptotic distribution of the variance estimator $\\sigma^2$ : \n",
    "\n",
    "$N \\longrightarrow \\infty,\\,\\,\\,\\,\\,\\,(N-1)\\,\\dfrac{S^2_{N-1}}{\\sigma^2}\\,\\sim \\, \\mathcal{\\chi}_{N-1}^2\\,\\,\\,\\,\\text{where}\\,\\,\\,\\,S^2_{N-1} = \\dfrac{1}{N-1} \\sum_{i=1}^N \\left(V_i-\\bar V\\right)^2$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Y_var_confidence_interval = (\n",
    "    Y_var * (sample_size - 1.) / ot.ChiSquare(sample_size - 1).computeQuantile((confidence_level) / 2.)[0],\n",
    "    Y_var * (sample_size - 1.) / ot.ChiSquare(sample_size - 1).computeQuantile((1. - confidence_level) / 2.)[0]\n",
    ")\n",
    "\n",
    "print( \"95%%-CI for the variance = [%.2f, %.2f]\" % Y_var_confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FOSM analysis\n",
    "\n",
    "The **first-order second-moment** approach is an alternative approximate method for calculating the mean and variance of the output variables.\n",
    "\n",
    "This method is based on a Taylor series expansion of the model $\\mathcal M$, in the vicinity of the input's mean $\\mathbf \\mu_X$ . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "FOSM_approximation = ot.TaylorExpansionMoments(Y_random_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Y_mean_FOSM_1st_order = FOSM_approximation.getMeanFirstOrder()[0]\n",
    "Y_mean_FOSM_2nd_order = FOSM_approximation.getMeanSecondOrder()[0]\n",
    "Y_var_FOSM = FOSM_approximation.getCovariance()[0, 0]\n",
    "Y_stdv_FOSM = np.sqrt(Y_var_FOSM)\n",
    "print(\"Mean 1st order     = %.2f\" % Y_mean_FOSM_1st_order)\n",
    "print(\"Mean 2nd order     = %.2f\" % Y_mean_FOSM_2nd_order)\n",
    "print(\"Variance           = %.2f\" % Y_var_FOSM)\n",
    "print(\"Standard deviation = %.2f\" % Y_stdv_FOSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analysis of variance\n",
    "\n",
    "## FOSM importance factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "FOSM_importance_factors = FOSM_approximation.getImportanceFactors()\n",
    "FOSM_importance_factors_graph = FOSM_approximation.drawImportanceFactors()\n",
    "FOSM_importance_factors_graph.setTitle(\"FOSM importance factors\")\n",
    "_ = View(FOSM_importance_factors_graph, figure=pl.figure(figsize=(6, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graphical sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's get the cached function calls... and concatenate all sample together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cached_inputs = model.getCacheInput()\n",
    "cached_outputs = model.getCacheOutput()\n",
    "\n",
    "all_sample = cached_inputs[:]\n",
    "all_sample.stack(cached_outputs)\n",
    "all_sample.setDescription(model.getDescription())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... And make **scatter plots** out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots(figsize=(14, 14))\n",
    "View(ot.Pairs(all_sample), plot_kwargs={'marker':'.'}, axes=[ax])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "... Or a **Cobweb plot**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cobweb_plot = ot.VisualTest_DrawCobWeb(\n",
    "    cached_inputs,\n",
    "    cached_outputs,\n",
    "    Y_mean - 0.1 * Y_stdv,\n",
    "    Y_mean + 0.2 * Y_stdv,\n",
    "    \"red\",\n",
    "    False,\n",
    ")\n",
    "_ = View(cobweb_plot, figure=pl.figure(figsize=(12, 8)))"
   ]
  }
 ],
 "metadata": {
  "css": [
   ""
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
