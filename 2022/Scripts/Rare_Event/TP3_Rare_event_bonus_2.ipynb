{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagation d'incertitude : Fiabilité (complément)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce *notebook* apporte des compléments concernant les méthodes FORM et tirages d'importance lorsqu'on est en présence de plusieurs points de défaillance le plus probable. Les solutions consistent à utiliser la méthode FORM système ou bien les tirages d'importance avec une densité instrumentale dirigée vers les 2 points $P^*$.\n",
    "\n",
    "Les deux méthodes sont appliquées sur l'exemple de Der Kiureghian & Dakessian qui présente justement deux points $P^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openturns as ot\n",
    "from openturns.viewer import View\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%pylab --no-import-all inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "rcParams = { 'axes.grid': False,\n",
    "             #'axes.hold': True,\n",
    "             'axes.labelsize': 16,\n",
    "             'xtick.labelsize': 12,\n",
    "             'ytick.labelsize': 12,\n",
    "             'axes.linewidth': 0.5,\n",
    "             'font.size': 16,\n",
    "             'image.cmap': 'gray',\n",
    "             'image.interpolation': 'bilinear',\n",
    "             'legend.fontsize': 16,\n",
    "             'legend.shadow': True,\n",
    "             'lines.linewidth': 1.5}\n",
    "plt.rcParams.update(rcParams)\n",
    "light_gray = plt.matplotlib.colors.LinearSegmentedColormap.from_list(\n",
    "                'light_gray', [[.9] * 3, [.6] * 3])\n",
    "class FormatFaker(object):\n",
    "    def __init__(self, str): self.str = str\n",
    "    def __mod__(self, stuff): return self.str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Kiureghian & Dakessian (1998)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un exemple à deux \"points de défaillance les plus probables\" pour montrer les limites des approches basées sur l'hypothèse d'unicité d'un tel point (FORM, SORM, et MPFP-IS)\n",
    "\n",
    "Dans cet exemple, la fonction d'état-limite est définie comme suit:\n",
    "\n",
    "$g(x_1, x_2) = b - x_2 - \\kappa\\,(x_1 - e) ^ 2$,\n",
    "\n",
    "et $\\mathbf{X} \\sim \\mathcal{N}_2(\\mathbf{0}, \\mathbf{1})$.\n",
    "\n",
    "Le paramètre d'excentricité $e > 0$ permet de favoriser l'influence un point de défaillance plutôt qu'un autre dans la probabilité, le coefficient $\\kappa > 0$ contrôle la courbure de l'état-limite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_distribution = ot.Normal(2)\n",
    "\n",
    "def g_(X):\n",
    "    X = np.atleast_2d(X)\n",
    "    b, kappa, e = 5., .5, .1\n",
    "    return np.atleast_2d(b - X[:, 1] - kappa * (X[:, 0] - e) ** 2.).T\n",
    "f = ot.PythonFunction(n=2, p=1, func_sample=g_)\n",
    "g = ot.MemoizeFunction(f)\n",
    "g.setGradient(\n",
    "    ot.NonCenteredFiniteDifferenceGradient(\n",
    "        np.array(input_distribution.getStandardDeviation()) * 1e-2,\n",
    "        g.getEvaluation()))\n",
    "g.setHessian(\n",
    "    ot.CenteredFiniteDifferenceHessian(\n",
    "        np.array(input_distribution.getStandardDeviation()) * 1e-2,\n",
    "        g.getEvaluation()))\n",
    "\n",
    "G = ot.CompositeRandomVector(g, ot.RandomVector(input_distribution))\n",
    "\n",
    "failure = ot.ThresholdEvent(G, ot.LessOrEqual(), 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transformation isoprobabiliste et représentations 2D du problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_in_standard_space(lim=6, res=50, ax=None, g0=0., approx=None):\n",
    "    if ax is None:\n",
    "        ax = plt.figure(figsize=(8, 8)).add_subplot(111)\n",
    "    u1_plot, u2_plot = np.meshgrid(np.linspace(-lim, lim, res), np.linspace(-lim, lim, res))\n",
    "    uu_plot = np.vstack([u1_plot.ravel(), u2_plot.ravel()]).T\n",
    "    Tinv = input_distribution.getInverseIsoProbabilisticTransformation()\n",
    "    gu_plot = np.reshape(g(Tinv(uu_plot)), (res, res))\n",
    "    fu_plot = np.reshape(ot.Normal(2).computePDF(uu_plot), (res, res))\n",
    "    im = ax.imshow(np.flipud(fu_plot), cmap=light_gray, extent=(-lim, lim, -lim, lim))\n",
    "    cb = plt.colorbar(im)\n",
    "    cb.set_label('$\\\\varphi(\\mathbf{u})$')\n",
    "    ax.contourf(u1_plot, u2_plot, gu_plot, [-np.inf, g0], colors='r', alpha=.2)\n",
    "    c = ax.contour(u1_plot, u2_plot, gu_plot, [g0], colors='r', linestyles='solid', lw=2.)\n",
    "    plt.clabel(c, fmt=FormatFaker('$g^{\\circ}(\\mathbf{u}) = %.2f$' % g0), colors='k')\n",
    "    if approx is not None:\n",
    "        for app in approx:\n",
    "            approx_plot = np.reshape(app(uu_plot), (res, res))\n",
    "            ax.contour(u1_plot, u2_plot, approx_plot, [g0], colors='b', linestyles='--', lw=2.)\n",
    "            ax.contourf(u1_plot, u2_plot, approx_plot, [-np.inf, g0], colors='b', alpha=.2)\n",
    "    ax.set_title('Standard space')\n",
    "    ax.set_xlim(-lim, lim)\n",
    "    ax.set_ylim(-lim, lim)\n",
    "    ax.set_aspect(1.)\n",
    "    ax.set_xlabel('$u_1$')\n",
    "    ax.set_ylabel('$u_2$')\n",
    "    origin = np.zeros(2)\n",
    "    ax.plot(origin[0], origin[1], 'k.', markersize=15)\n",
    "    plt.text(origin[0], origin[1], '$\\mathbf{O}$', ha='left', va='bottom', fontdict={'fontsize': 14})\n",
    "    plt.axvline(origin[0], color='k', linestyle='dashdot', linewidth=1.)\n",
    "    plt.axhline(origin[1], color='k', linestyle='dashdot', linewidth=1.)\n",
    "    return ax, locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_in_physical_space(lim=6, res=50, ax=None, g0=0.):\n",
    "    if ax is None:\n",
    "        ax = plt.figure(figsize=(8, 8)).add_subplot(111)\n",
    "    x1_lim = (input_distribution.getMarginal(0).computeQuantile(ot.Normal().computeCDF(-lim))[0],\n",
    "              input_distribution.getMarginal(0).computeQuantile(1. - ot.Normal().computeCDF(-lim))[0])\n",
    "    x2_lim = (input_distribution.getMarginal(1).computeQuantile(ot.Normal().computeCDF(-lim))[0],\n",
    "              input_distribution.getMarginal(1).computeQuantile(1. - ot.Normal().computeCDF(-lim))[0])\n",
    "    x1_plot, x2_plot = np.meshgrid(np.linspace(x1_lim[0], x1_lim[1], res),\n",
    "                                   np.linspace(x2_lim[0], x2_lim[1], res))\n",
    "    xx_plot = np.vstack([x1_plot.ravel(), x2_plot.ravel()]).T\n",
    "    gx_plot = np.reshape(g(xx_plot), (res, res))\n",
    "    fx_plot = np.reshape(input_distribution.computePDF(xx_plot), (res, res))\n",
    "    im = ax.imshow(np.flipud(fx_plot), cmap=light_gray, extent=(x1_lim[0], x1_lim[1], x2_lim[0], x2_lim[1]))\n",
    "    cb = plt.colorbar(im)\n",
    "    cb.set_label('$f_{\\mathbf{X}}(\\mathbf{x})$')\n",
    "    ax.contourf(x1_plot, x2_plot, gx_plot, [-np.inf, g0], colors='r', alpha=.2)\n",
    "    c = ax.contour(x1_plot, x2_plot, gx_plot, [g0], colors='r', linestyles='solid', lw=2.)\n",
    "    plt.clabel(c, fmt=FormatFaker('$g(\\mathbf{x}) = %.2f$' % g0), colors='k')\n",
    "    ax.set_title('Physical space')\n",
    "    ax.set_xlim(*x1_lim)\n",
    "    ax.set_ylim(*x2_lim)\n",
    "    #ax.set_aspect(np.diff(x1_lim) / np.diff(x2_lim))\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "    median = input_distribution.computeQuantile(.5)\n",
    "    ax.plot(median[0], median[1], 'k.', markersize=15)\n",
    "    plt.text(median[0], median[1], '$\\mathbf{X}_{50\\%}$', ha='left', va='bottom', fontdict={'fontsize': 14})\n",
    "    plt.axvline(median[0], color='k', linestyle='dashdot', linewidth=1.)\n",
    "    plt.axhline(median[1], color='k', linestyle='dashdot', linewidth=1.)\n",
    "    return ax, locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "ax, data_plot = plot_in_physical_space(res=100, ax=fig.add_subplot(121))\n",
    "ax.contour(data_plot['x1_plot'], data_plot['x2_plot'], data_plot['fx_plot'], cmap=plt.matplotlib.cm.jet)\n",
    "ax, data_plot_st = plot_in_standard_space(ax=fig.add_subplot(122), lim=8.)\n",
    "ax.contour(data_plot_st['u1_plot'], data_plot_st['u2_plot'], data_plot_st['fu_plot'], cmap=plt.matplotlib.cm.jet)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Surface dans l'espace physique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = Axes3D(fig)\n",
    "ax.plot_surface(data_plot['x1_plot'], data_plot['x2_plot'], data_plot['gx_plot'],\n",
    "                cmap=plt.matplotlib.cm.jet, rstride=1, cstride=1, lw=0.)\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('$g(\\mathbf{x})$')\n",
    "ax.set_title('Physical space')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Surface dans l'espace standard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = Axes3D(fig)\n",
    "ax.plot_surface(data_plot_st['u1_plot'], data_plot_st['u2_plot'], data_plot_st['gu_plot'],\n",
    "                cmap=plt.matplotlib.cm.jet, rstride=1, cstride=1, lw=0.)\n",
    "ax.set_xlabel('$u_1$')\n",
    "ax.set_ylabel('$u_2$')\n",
    "ax.set_zlabel('$g(\\mathbf{u})$')\n",
    "ax.set_title('Standard space')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estimation par simple simulation de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation de l'historique\n",
    "g.enableHistory()\n",
    "g.clearHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de l'objet MonteCarlo\n",
    "MCS_algorithm = ot.ProbabilitySimulationAlgorithm(failure)\n",
    "\n",
    "# Fixe le coefficient de variation maximum à 30%\n",
    "MCS_algorithm.setMaximumCoefficientOfVariation(.05)\n",
    "\n",
    "# Fixe le nombre de tirage à MaximumOuterSampling x BlockSize\n",
    "MCS_algorithm.setMaximumOuterSampling(int(1e4))\n",
    "# Blocksize permet d'envoyer par paquet les points à évaluer\n",
    "MCS_algorithm.setBlockSize(int(1e2)) \n",
    "\n",
    "# Lancement de la simulation\n",
    "MCS_algorithm.run()\n",
    "MCS_results = MCS_algorithm.getResult()\n",
    "\n",
    "# Récupération du nombre d'évaluations\n",
    "MCS_evaluation_number = g.getEvaluationCallsNumber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability estimate: %.3e' % MCS_results.getProbabilityEstimate())\n",
    "print('Coefficient of variation: %.2f' % MCS_results.getCoefficientOfVariation())\n",
    "print('Number of evaluations: %d' % MCS_evaluation_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Affichage des tirages dans les espaces physique et standard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Récupération des tirages et la valeur de g en ces points\n",
    "input_sample = np.array(g.getInputHistory())[:int(1e4)]\n",
    "output_sample = np.ravel(g.getOutputHistory())[:int(1e4)]\n",
    "\n",
    "# Plot espace physique\n",
    "ax, data_plot = plot_in_physical_space(ax=fig.add_subplot(121))\n",
    "ax.plot(input_sample[output_sample > 0., 0], input_sample[output_sample > 0., 1], 'b.')\n",
    "ax.plot(input_sample[output_sample <= 0., 0], input_sample[output_sample <= 0., 1], 'rx')\n",
    "\n",
    "# plot espace standard\n",
    "ax, data_plot = plot_in_standard_space(ax=fig.add_subplot(122))\n",
    "# Attention, il faut utiliser la méthode getIsoProbabilisticTransformation pour transformer\n",
    "# les variables d'entrée dans l'espace standard\n",
    "input_sample = np.array(input_distribution.getIsoProbabilisticTransformation()(input_sample))\n",
    "ax.plot(input_sample[output_sample > 0., 0], input_sample[output_sample > 0., 1], 'b.')\n",
    "ax.plot(input_sample[output_sample <= 0., 0], input_sample[output_sample <= 0., 1], 'rx')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Approches basées sur le point de défaillance le plus probable\n",
    "\n",
    "Dans le but d'appliquer la méthode FORM système, il existe un algorithme, appelé multi FORM, qui permet de trouver plusieurs points $P^*$. Pour cet exemple, l'algorithme classique est utilisé en faisant varier uniquement le point de départ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.enableHistory()\n",
    "g.clearHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spécification de la fonction contrainte, dans l'espace standard !!!\n",
    "Tinv = input_distribution.getInverseIsoProbabilisticTransformation()\n",
    "\n",
    "# Définition du problème d'optimisation\n",
    "gt = ot.ComposedFunction(g, Tinv)\n",
    "optimProblem = ot.NearestPointProblem(gt, 0.)\n",
    "\n",
    "## Algorithme AbdoRackwitz\n",
    "design_point_algorithm = ot.AbdoRackwitz(optimProblem)\n",
    "\n",
    "# Point de départ multiples fixé manuellement\n",
    "design_point_in_physical_space = list()\n",
    "design_point_in_standard_space = list()\n",
    "start_points = [[0., 0.], [1, 1]]\n",
    "for point in start_points:\n",
    "    design_point_algorithm.setStartingPoint(point)\n",
    "    design_point_algorithm.run()\n",
    "    search_results = design_point_algorithm.getResult()\n",
    "    design_point_in_standard_space.append(search_results.getOptimalPoint())\n",
    "    design_point_in_physical_space.append(Tinv(design_point_in_standard_space[-1]))\n",
    "design_point_in_physical_space = np.array(design_point_in_physical_space)\n",
    "design_point_in_standard_space = np.array(design_point_in_physical_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_point_in_standard_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapprox = []\n",
    "ustar0 = design_point_in_standard_space[0]\n",
    "def g0py0(u):\n",
    "    g0 = g.gradient(Tinv(ustar0)).transpose() * (u - ustar0)\n",
    "    return g0\n",
    "gapprox.append(ot.PythonFunction(2, 1, g0py0))\n",
    "ustar1 = design_point_in_standard_space[1]\n",
    "def g0py1(u):\n",
    "    g0 = g.gradient(Tinv(ustar1)).transpose() * (u - ustar1)\n",
    "    return g0\n",
    "gapprox.append(ot.PythonFunction(2, 1, g0py1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "# plot espace physique\n",
    "ax, data_plot = plot_in_physical_space(ax=fig.add_subplot(121))\n",
    "ax.plot([input_distribution.computeQuantile(.5)[0], design_point_in_physical_space[0, 0]],\n",
    "        [input_distribution.computeQuantile(.5)[1], design_point_in_physical_space[0, 1]], 'b-')\n",
    "ax.plot([input_distribution.computeQuantile(.5)[0], design_point_in_physical_space[1, 0]],\n",
    "        [input_distribution.computeQuantile(.5)[1], design_point_in_physical_space[1, 1]], 'b-')\n",
    "ax.plot(design_point_in_physical_space[:, 0], design_point_in_physical_space[:, 1],\n",
    "        'b.', markersize=15)\n",
    "plt.text(design_point_in_physical_space[0, 0], design_point_in_physical_space[0, 1],\n",
    "        '$\\mathbf{x}_1^{*}$', ha='left', va='bottom', color='b', fontdict={'fontsize': 14})\n",
    "plt.text(design_point_in_physical_space[1, 0], design_point_in_physical_space[1, 1],\n",
    "        '$\\mathbf{x}_2^{*}$', ha='left', va='bottom', color='b', fontdict={'fontsize': 14})\n",
    "# plot espace standard\n",
    "ax, data_plot = plot_in_standard_space(ax=fig.add_subplot(122), approx=gapprox)\n",
    "ax.plot([0., design_point_in_standard_space[0, 0]],\n",
    "        [0., design_point_in_standard_space[0, 1]], 'b-')\n",
    "ax.plot([0., design_point_in_standard_space[1, 0]],\n",
    "        [0., design_point_in_standard_space[1, 1]], 'b-')\n",
    "ax.plot(np.array(design_point_in_standard_space)[:, 0], \n",
    "        np.array(design_point_in_standard_space)[:, 1],\n",
    "        'b.', markersize=15)\n",
    "plt.text(design_point_in_standard_space[0, 0], design_point_in_standard_space[0, 1],\n",
    "        '$\\mathbf{u}_1^{*}$', ha='left', va='bottom', color='b', fontdict={'fontsize': 14})\n",
    "plt.text(design_point_in_standard_space[1, 0], design_point_in_standard_space[1, 1],\n",
    "        '$\\mathbf{u}_2^{*}$', ha='left', va='bottom', color='b', fontdict={'fontsize': 14})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. First order reliability method system\n",
    "\n",
    "Il est possible de prendre en compte plusieurs points $P^*$ et de calculer une probabilité système prendant en compte plusieurs état-limites linéaires (approximés). La probabilité se calcule comme suit dans le cas d'un système série (union des domaines) :\n",
    "\n",
    "\\begin{equation}\n",
    "    p_{f, FORM SYS} = 1 - \\Phi_n (\\boldsymbol \\beta_{HL}; \\boldsymbol \\rho)\n",
    "\\end{equation}\n",
    "\n",
    "où $\\boldsymbol \\beta_{HL}$ est l'ensemble des indices de fiabilité associés à chaque point $P^*$ considéré, et $\\boldsymbol \\rho$ représente la corrélation entre les état-limites : $ \\rho_{ij} = \\boldsymbol \\alpha^{(i)t} \\boldsymbol \\alpha^{(j)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du vecteur beta à partir des coordonnées u*\n",
    "Beta = np.sqrt(np.sum(design_point_in_standard_space**2, axis=1))\n",
    "\n",
    "# Calcul des vecteurs alpha associés à chaque P*\n",
    "alpha = [design_point_in_standard_space[i] / Beta[i] for i in range(2)]\n",
    "\n",
    "# calcul de la matrice de corrélation rho\n",
    "rho = ot.CorrelationMatrix(2)\n",
    "rho[1,0] = np.dot(alpha[0], alpha[1])\n",
    "\n",
    "# Calcul de la probabilité de défaillance à partir de la multinormale en dimension 2\n",
    "# avec la corrélation rho\n",
    "multiNor = ot.Normal(ot.Point([0,0]),ot.Point([1,1]),\n",
    "                     ot.CorrelationMatrix(rho))\n",
    "Pfsys = 1 - multiNor.computeCDF(Beta)\n",
    "\n",
    "print('Hasofer-Lind reliability index: ', Beta)\n",
    "print('First-order approximation of the probability: %.3e' % Pfsys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Echantillonnage préférentiel au point de défaillance le plus probable (Tirages d'importance, MPFP-IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.enableHistory()\n",
    "g.clearHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la densité instrumentale : mixture de 2 lois normales centrées chacune sur un des points P*\n",
    "corr = ot.IdentityMatrix(2)\n",
    "DistributionTirage1 = ot.Normal(design_point_in_standard_space[0], corr)\n",
    "DistributionTirage2 = ot.Normal(design_point_in_standard_space[1], corr)\n",
    "instrumental_distribution = ot.Mixture([DistributionTirage1, DistributionTirage2])\n",
    "\n",
    "# Création de l'objet ImportanceSampling avec :\n",
    "#  - l'événement dans l'espace standard (--> fonction de performance définie dans l'espace standard)\n",
    "#  - la densité instrumentale\n",
    "experiment = ot.ImportanceSamplingExperiment(instrumental_distribution)\n",
    "IS_algorithm = ot.ProbabilitySimulationAlgorithm(failure, experiment)\n",
    "IS_algorithm.setMaximumCoefficientOfVariation(.05)\n",
    "IS_algorithm.setMaximumOuterSampling(int(1e3))\n",
    "IS_algorithm.setBlockSize(int(1e1))\n",
    "IS_algorithm.run()\n",
    "IS_results = IS_algorithm.getResult()\n",
    "IS_evaluation_number = g.getEvaluationCallsNumber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability estimate: %.3e' % IS_results.getProbabilityEstimate())\n",
    "print('Coefficient of variation: %.2f' % IS_results.getCoefficientOfVariation())\n",
    "print('Number of evaluations: %d' % IS_evaluation_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "View(IS_algorithm.drawProbabilityConvergence(), figure_kwargs={'figsize':(10,6)}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "input_sample = np.array(g.getInputHistory())\n",
    "output_sample = np.ravel(g.getOutputHistory())\n",
    "ax, data_plot = plot_in_physical_space(ax=fig.add_subplot(121))\n",
    "ax.plot(input_sample[output_sample > 0., 0], input_sample[output_sample > 0., 1], 'b.')\n",
    "ax.plot(input_sample[output_sample <= 0., 0], input_sample[output_sample <= 0., 1], 'rx')\n",
    "ax, data_plot = plot_in_standard_space(ax=fig.add_subplot(122))\n",
    "input_sample = np.array(input_distribution.getIsoProbabilisticTransformation()(input_sample))\n",
    "ax.contour(data_plot['u1_plot'], data_plot['u2_plot'],\n",
    "           np.reshape(instrumental_distribution.computePDF(data_plot['uu_plot']),\n",
    "                      data_plot['u1_plot'].shape),\n",
    "           cmap=plt.matplotlib.cm.jet)\n",
    "ax.plot(input_sample[output_sample > 0., 0], input_sample[output_sample > 0., 1], 'b.')\n",
    "ax.plot(input_sample[output_sample <= 0., 0], input_sample[output_sample <= 0., 1], 'rx')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
